<chapter xml:id="Tuning"
	 xmlns:xlink="http://www.w3.org/1999/xlink">
  <title>Tuning</title>
  <section>
    <title>Introduction</title>
    <para>
      This chapter contains imformation useful to obtain the best performance
      of the LIXA state server (<command>lixad</command>) in your environment.
      As explained in <xref linkend="Configuring_the_server"/> the server
      provide some configuration parameters that can be tuned.
    </para>
    <para>
      There are basically two tuning paths:
      <itemizedlist mark='bullet'>
	<listitem><para>
	  number of server threads: the level of internal parallelism can be
	  tuned according with the number of available CPUs
	</para></listitem>
	<listitem><para>
	  disk performance: several parameters are available to find the best
	  trade off between performance and reliability
	</para></listitem>
      </itemizedlist>
      The two tuning paths are typically not fully independent: increasing the
      number of server threads increases the pressure to the disk(s) and vice
      versa.
    </para>
    <section>
      <title>Number of server threads</title>
      <para>
	The LIXA state server is a multi-threaded process with one network
	listener and many <quote>managers</quote>; every manager runs
	in a dedicated thread. Choosing the optimal number of threads requires
	some trials: following the <quote>just work</quote> concept
	the default configuration specifies 3 threads, but your 
	installation might perform better using a different number (in the
	next paragraphs you can collect some hints).
      </para>
      <note><para>
	If you use the <emphasis>journal based</emphasis> state engine, 
	<command>lixad</command> will start 3 different POSIX threads for every
	server thread; if you use the <emphasis>traditional</emphasis> state
	engine, <command>lixad</command> will start a single POSIX thread for
	every server thread.
      </para></note>
      <para>
	Refer to <xref linkend="Configuring_the_server"/> for information about
	how to specify the number of server threads.
      </para>
    </section>
    <section>
      <title>Disk performance</title>
      <para>
	To get the best IO performance, <command>lixad</command> provides 3
	complementary strategies:
	<itemizedlist mark='bullet'>
	  <listitem><para>
	    scattering IO through different disks: every server thread points
	    its own set of state files, if your system provides independent
	    disks, you can assign them to different server threads
	  </para></listitem>
	  <listitem><para>
	    choosing the state engine type: two state engines,
	    <emphasis>traditional</emphasis> and
	    <emphasis>journal based</emphasis>; the first has
	    a proven track of reliability because it has been deployed in
	    production environments since 2009 while the latter is a new
	    engine released in 2020 and provides amazingly low latency
	  </para></listitem>
	  <listitem><para>
	    configuring the state engine: depending on the previous choice,
	    different options are available to optimize the performance of
	    the state engine
	  </para></listitem>
	</itemizedlist>
      </para>
    </section>
  </section>
  <section>
    <title>Scattering IO through different disks</title>
    <para>
      As explained in <xref linkend="Configuring_the_server"/> every
      manager inside the LIXA state server uses a specific path for
      its status files. If you specify path associated to independent
      disks, you will obtain I/O independence for every the LIXA
      server thread.
    </para>
    <para>
      The path specified can be a directory name (it must terminate with a
      slash) or the prefix of a file name. Different server threads must
      specify different paths.
    </para>
    <important><para>
      This approach provided benefits in the age of physical servers with RAID
      disk array controllers and spinning disks, but is no more actual for many
      storage configurations. In some configurations, like for example
      Microsoft Azure public cloud, the number of IOPS (Input Output
      Operations Per Second) depends on the type and the size of the virtual
      block device; the
      same applies to some enterprise storage system for on-premises
      datacenters. This optimization strategy is valuable only if many small
      disks support an higher number of IOPS in comparison with a single large
      disk.
    </para></important>
  </section>
  <section>
    <title>Choosing the state engine type</title>
    <para>
      <emphasis>Journal based</emphasis> state engine has been designed to
      provide a better alternative to the <emphasis>traditional</emphasis>
      state engine. 
      From a performance point of view, the <emphasis>journal based</emphasis>
      state engine provides better results in most situations; nevertheless,
      due to the
      proven robustness, it's expected the usage of the
      <emphasis>traditional</emphasis> state
      engine will continue for some time, especially when high performance
      is not a must.
    </para>
    <para>
      Independently from the chosen state engine, some common concept requires
      understanding to operate an aware choice.
    </para>
    <para>
      First of all, the LIXA state server does not persist the data used by
      the Application Program, it only persists the state of the transactions.
      In the event that the state of a transaction is not preserved, you
      don't miss the data, but the state of the transaction that was
      manipulating the data.
      The direct consequence of the previous statement is that: in the worst
      case, if LIXA state server miss the state of the transaction, you have
      to rollback or commit the transaction manually. This is obviously not a
      situation you want to frequently have in your normal operations and this
      is why LIXA state server provides the highest level of resiliency.
    </para>
    <para>
      If you want to be 100% sure you don't miss the state of the transaction,
      you must be 100% sure that the state of the transaction has been
      recorded in a durable way, typically in some storage device.
      Writing storage, even the fastest storage, is still a quite slow
      operation in comparison with other communication and computing
      operations. 
      Very high performance storage can provide write latency below 1ms, but
      in a typical production environment, having 5ms write latency to the
      storage subsystem can be considered a good scenario.
      Incredibly enough, 5ms are a huge time for contemporary computing and
      contemporary networking.
    </para>
    <para>
      To make a long story short, this is a typical trade-off between speed
      and safety: the faster you go, the less safe you can be.
      In a real case scenario, 100% safety is unlikely to be the best choice:
      it's capped by the technology limits and it risks to unnecessarily slow
      down your whole system. 
    </para>
    <para>
      The good news is that the LIXA state engines, both journal and
      traditional, provide parameters to tune the behavior.
    </para>
    <section xml:id="Tuning_the_journal_state_engine">
      <title>Tuning the journal state engine</title>
      <para>
	The journal state engine provides two levels of resilience with two
	different Recovery Point Objectives depending on the type of crash
	encountered by the LIXA state server.
      </para>
      <section>
	<title>Soft crash RPO</title>
	<para>
	  A <emphasis>soft crash</emphasis> is a crash that happens to the
	  LIXA state server process (<command>lixad</command>), but it does not
	  break the operating system. Common examples are:
	  <itemizedlist mark='bullet'>
	    <listitem><para>
	      killing <command>lixad</command>
	    </para></listitem>
	    <listitem><para>
	      <command>lixad</command> crashes due to some unexpected reason
	    </para></listitem>
	  </itemizedlist>
	  In the event of a <emphasis>soft crash</emphasis>, the restart
	  usually happens from the last active state table file without any
	  data miss. As a consequence, when restart from the last active
	  state table succeeds, the RPO is zero and there's no transaction
	  state missing.
	</para>
      </section>
      <section>
	<title>Hard crash RPO</title>
	<para>
	  A <emphasis>hard crash</emphasis> is a crash related to the
	  operating system or a damage to state table files. Common examples
	  are:
	  <itemizedlist mark='bullet'>
	    <listitem><para>
	      operating system / hypervisor crashes
	    </para></listitem>
	    <listitem><para>
	      hardware failure
	    </para></listitem>
	    <listitem><para>
	      disk content corruption
	    </para></listitem>
	  </itemizedlist>
	  In the event of a <emphasis>hard crash</emphasis>, the restart
	  happens from the last consistent active state table file plus all
	  the available consistent state log records.
	</para>
	<para>
	  Due to different strategies of log flushing, the corresponding RPO
	  can be greater than zero.
	</para>
      </section>
      <section>
	<title>Impact of parameter <parameter>min_elapsed_sync_time</parameter></title>
	<para>
	  The parameter fixes the minimum delay between the need of a
	  transaction state flushing and the start of the I/O operation:
	  <itemizedlist mark='bullet'>
	    <listitem><para>
	      a low value slows down the <command>lixad</command> server
	      due to frequent asking for log flushing
	    </para></listitem>
	    <listitem><para>
	      a value greater than zero increases the RPO for 
	      <emphasis>hard crash</emphasis> by the same amount
	    </para></listitem>
	    <listitem><para>
	      to have a guaranteed RPO=0 in the event of
	      <emphasis>hard crash</emphasis>, this parameter must be set to
	      zero
	    </para></listitem>
	  </itemizedlist>
	</para>
      </section>
      <section>
	<title>Impact of parameter <parameter>max_elapsed_sync_time</parameter></title>
	<para>
	  The parameter fixes the maximum delay between the need of a
	  transaction state flushing and the start of the I/O operation:
	  <itemizedlist mark='bullet'>
	    <listitem><para>
	      a low value slows down the <command>lixad</command> server
	      due to frequent asking for log flushing
	    </para></listitem>
	    <listitem><para>
	      a value greater than zero increases the RPO for 
	      <emphasis>hard crash</emphasis> by the same amount
	    </para></listitem>
	    <listitem><para>
	      to have a guaranteed RPO=0 in the event of
	      <emphasis>hard crash</emphasis>, this parameter must be set to
	      zero
	    </para></listitem>
	  </itemizedlist>
	  The parameter must be greater or equal to
	  <parameter>min_elapsed_sync_time</parameter>: if both are set to
	  value zero, state log file is flushed as soon as a transaction needs
	  to persist a new state.
	</para>
      </section>
      <section>
	<title>Impact of parameter <parameter>log_size</parameter></title>
	<para>
	  The parameter specifies the desired amount of disk space that must
	  be used of every state log file. A state log file can be switched
	  only when the previous state table synchronization has been
	  completed. In presence of disks with high latency and high 
	  throughput, a larger value can be helpful to obtain better
	  performances.
	</para>
	<important>
	  <para>
	    Too large logs can produce adverse performances during state server
	    restart in a couple of situations:
	    <itemizedlist mark='bullet'>
	      <listitem><para>
		option <parameter>log_o_direct="1"</parameter> (O_DIRECT) is
		used
	      </para></listitem>
	      <listitem><para>
		the state server restart follows a system reboot
	      </para></listitem>
	    </itemizedlist>
	    In both cases, Linux operating system has not cached the log file
	    page and all the reading must be done by the storage devices. As a
	    rule of thumb, don't allocate a large log if there's no a valid
	    performance benefit, during normal activity, in doing it.
	  </para>
	</important>
	<para>
	  The parameter has no direct impact on RPO.
	</para>
      </section>
      <section>
	<title>Impact of parameter <parameter>max_buffer_log_size</parameter></title>
	<para>
	  The parameter specifies the quantity of RAM used as buffer for
	  log writing: under some circumstances, higher values can improve
	  performances.
	</para>
	<para>
	  The parameter has no direct impact on RPO.
	</para>
      </section>
      <section>
	<title>Impact of parameters <parameter>log_o_*</parameter></title>
	<para>
	  The parameters specify the corresponding flags that must be used for
	  writing the state log files; as a general rule, 
	  <parameter>log_o_direct="1"</parameter> (O_DIRECT) is faster than
	  <parameter>log_o_dsync="1"</parameter> (O_DSYNC) and
	  <parameter>log_o_dsync="1"</parameter> (O_DSYNC) is faster than
	  <parameter>log_o_sync="1"</parameter> (O_SYNC).
	</para>
	<important><para>
	  To be precise, only <parameter>log_o_sync=1</parameter> in
	  association with 
	  <parameter>min_elapsed_sync_time="0"</parameter> and
	  <parameter>max_elapsed_sync_time="0"</parameter> guarantees RPO=0
	  in the event of <emphasis>hard crash</emphasis> for every hardware
	  configuration, but such configuration limitates the performance of
	  the LIXA state server and introduce additional latency.
	</para>
	<para>
	  In real life scenarios, depending on the characteristics of the
	  storage subsystem, less restrictive options can be reasonably used.
	  The best configuration requires investigation on the specific
	  hardware configuration. The configuration provided by default can be
	  considered a starting point to adjust according to the user's needs.
	</para></important>
	<note><para>
	  Parameters <parameter>log_o_*</parameter> can be uses together, for
	  example you can specify both <parameter>log_o_direct="1"</parameter> 
	  and <parameter>log_o_dsync="1"</parameter> to combine the effects of
	  O_DIRECT and O_DSYNC flags for log I/O.
	</para></note>
      </section>
    </section>
    <section xml:id="Tuning_the_traditional_state_engine">
      <title>Tuning the traditional state engine</title>
      <para>
	The traditional state engine provides a single level of resilience
	and no difference among types of crash encountered by the LIXA state
	server.
      </para>
    <para>
      Only two parameters can be configured: 
      <parameter>min_elapsed_sync_time</parameter> and 
      <parameter>max_elapsed_sync_time</parameter> while the others are
      ignored.
    </para>
    <section>
      <title>Impact of parameter <parameter>min_elapsed_sync_time</parameter></title>
	<para>
	  The parameter fixes the minimum delay between the need of a
	  transaction state flushing and the start of the memory map sync
	  operation:
	  <itemizedlist mark='bullet'>
	    <listitem><para>
	      a low value slows down the <command>lixad</command> server
	      due to frequent asking for map syncing
	    </para></listitem>
	    <listitem><para>
	      a value greater than zero increases the RPO by the same amount
	    </para></listitem>
	    <listitem><para>
	      to have a guaranteed RPO=0 this parameter must be set to
	      zero
	    </para></listitem>
	  </itemizedlist>
	</para>
      </section>
      <section>
	<title>Impact of parameter <parameter>max_elapsed_sync_time</parameter></title>
	<para>
	  The parameter fixes the maximum delay between the need of a
	  transaction state flushing and the start of the memory map sync:
	  <itemizedlist mark='bullet'>
	    <listitem><para>
	      a low value slows down the <command>lixad</command> server
	      due to frequent asking for map syncing
	    </para></listitem>
	    <listitem><para>
	      a value greater than zero increases the RPO by the same amount
	    </para></listitem>
	    <listitem><para>
	      to have a guaranteed RPO=0 this parameter must be set to
	      zero
	    </para></listitem>
	  </itemizedlist>
	  The parameter must be greater or equal to
	  <parameter>min_elapsed_sync_time</parameter>: if both are set to
	  value zero, memory map is synchronized as soon as a transaction needs
	  to persist a new state.
	</para>
      </section>
    </section>
    <section>
      <title>Balancing performance and resilience</title>
      <para>
	The higher the value of RPO, the higher the chance
	you will have to perform manual recovery in the case of a server
	crash (manual recovery is explained in 
	<xref linkend="Manual_cold_recovery"/>).
      </para>
      <para>
	On the other hand, don't force RPO=0 if you don't have clear evidence
	that you need it: depending on your business requirements and your 
	hardware configuration, especially
	if you use the <emphasis>journal based state engine</emphasis>, the
	need for RPO=0 might be not necessary.
	<link xlink:href="https://www.tiian.org/lixa/">LIXA web site</link>
	contains detailed performance analysis of a couple of possible
	deployment models: refers to the following links to figure out how the
	performances are influenced by the configuration parameters.
      </para>
      <para>
	The <link xlink:href="https://www.tiian.org/lixa/performances/performances.html">first architecture</link> applies to traditional environments with
	monolithic applications distributed in different tiers: the
	Application Program and the LIXA state server run in different
	virtual machines. The figures show that the highest the RPO, the
	lowest the total latency introduced by LIXA in managing
	distributed transactions.
      </para>
      <para>
	The <link xlink:href="https://www.tiian.org/lixa/performances/performances_2.html">second architecture</link> applies to microservices environments
	with a sidecar approach, typical of Kubernetes deployments: the
	Application Program and the LIXA state server run in the same
	virtual machine (and in the same pod in a Kubernetes configuration).
	Even for this type of architecture the figures show that the highest
	the RPO, the lowest the total latency introduced by LIXA in managing
	distributed transactions. Furtherly, this second type of architecture
	exhibits a lower latency than the first type.
      </para>
    </section>
    <section>
      <title>Conclusions</title>
      <para>
	LIXA configuration parameters allow fine tuning of the state engine; in
	a real life environment, apply the following guidelines:
	<itemizedlist mark='bullet'>
	  <listitem><para>
	    use default configuration for
	    <emphasis>traditional state engine</emphasis>, if you want to be
	    conservative, or <emphasis>journal based state engine</emphasis>,
	    if you want to be innovative
	  </para></listitem>
	  <listitem><para>
	    choose the proper deployment architecture: "client/server" or
	    "colocated" depending on your application architecture
	  </para></listitem>
	  <listitem><para>
	    in the event of scalability issues, you need to manager a huge
	    number of
	    Transactions per Second, split the workload in several 
	    LIXA state servers that work indipendently
	  </para></listitem>
	  <listitem><para>
	    in the event of latency issues, you need a very low latency,
	    understand if an higher RPO fits your requirements; if no,
	    split the workload in several LIXA state servers that work
	    indipendently: the figures show that the latency is strictly
	    correlated with the number of Transactions per Second managed by
	    the state server
	  </para></listitem>
	  <listitem><para>
	    if you use the
	    <emphasis>journal based state engine</emphasis>, monitor syslog
	    messages: the engine generates useful messages if the storage
	    configuration is not optimized
	  </para></listitem>
	</itemizedlist>
      </para>
    </section>
  </section>
</chapter>
